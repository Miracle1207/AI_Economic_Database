{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11cd204e60647f9a58c474894f150d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re \n",
    "import string\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 100\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts very alarming.|||Sex can be boring if it's in the sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/watch?v=fHiGbolFFGw|||Of course, to which I say I kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the other day.  Esoteric gabbing about the nature of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconception. That approaching is logically is going to b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  \\\n",
       "0  INFJ   \n",
       "1  ENTP   \n",
       "2  INTP   \n",
       "3  INTJ   \n",
       "4  ENTJ   \n",
       "\n",
       "                                                                                                 posts  \n",
       "0  'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1ro...  \n",
       "1  'I'm finding the lack of me in these posts very alarming.|||Sex can be boring if it's in the sam...  \n",
       "2  'Good one  _____   https://www.youtube.com/watch?v=fHiGbolFFGw|||Of course, to which I say I kno...  \n",
       "3  'Dear INTP,   I enjoyed our conversation the other day.  Esoteric gabbing about the nature of th...  \n",
       "4  'You're fired.|||That's another silly misconception. That approaching is logically is going to b...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8675, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFP    1832\n",
       "INFJ    1470\n",
       "INTP    1304\n",
       "INTJ    1091\n",
       "ENTP     685\n",
       "ENFP     675\n",
       "ISTP     337\n",
       "ISFP     271\n",
       "ENTJ     231\n",
       "ISTJ     205\n",
       "ENFJ     190\n",
       "ISFJ     166\n",
       "ESTP      89\n",
       "ESFP      48\n",
       "ESFJ      42\n",
       "ESTJ      39\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_r1(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http[^\\s]*','',text)  # remove urls only\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.posts = df.posts.apply(clean_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>' and intj moments    sportscenter not top ten plays    pranks|||what has been the most life-cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'i'm finding the lack of me in these posts very alarming.|||sex can be boring if it's in the sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'good one  _____    course, to which i say i know; that's my blessing and my curse.|||does being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'dear intp,   i enjoyed our conversation the other day.  esoteric gabbing about the nature of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'you're fired.|||that's another silly misconception. that approaching is logically is going to b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  \\\n",
       "0  INFJ   \n",
       "1  ENTP   \n",
       "2  INTP   \n",
       "3  INTJ   \n",
       "4  ENTJ   \n",
       "\n",
       "                                                                                                 posts  \n",
       "0  ' and intj moments    sportscenter not top ten plays    pranks|||what has been the most life-cha...  \n",
       "1  'i'm finding the lack of me in these posts very alarming.|||sex can be boring if it's in the sam...  \n",
       "2  'good one  _____    course, to which i say i know; that's my blessing and my curse.|||does being...  \n",
       "3  'dear intp,   i enjoyed our conversation the other day.  esoteric gabbing about the nature of th...  \n",
       "4  'you're fired.|||that's another silly misconception. that approaching is logically is going to b...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if urls are removed\n",
    "\n",
    "for post in df.posts:\n",
    "    if 'http' in post:\n",
    "        print(post)        # return empty if none was found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data cleaning - Word contraction\n",
    "\n",
    "words that are contracted are expanded to its full form. eg \n",
    "- I'm : I am, \n",
    "- you're : you are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contract</th>\n",
       "      <th>full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ain't</td>\n",
       "      <td>are not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aren't</td>\n",
       "      <td>are not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can't</td>\n",
       "      <td>can not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>could've</td>\n",
       "      <td>could have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>couldn't</td>\n",
       "      <td>could not</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   contract        full\n",
       "0     ain't     are not\n",
       "1    aren't     are not\n",
       "2     can't     can not\n",
       "3  could've  could have\n",
       "4  couldn't   could not"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_contraction = pd.read_csv('list of contraction.csv')      # list of contracted form to expanded form\n",
    "word_contraction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_contraction_diction = dict(zip(word_contraction.contract,word_contraction.full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_word(text):\n",
    "    for k,v in word_contraction_diction.items():\n",
    "        if k in text:                                # \n",
    "            text = text.replace(k,v)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.posts = df.posts.apply(expand_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>' and intj moments    sportscenter not top ten plays    pranks|||what has been the most life-cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'i am finding the lack of me in these posts very alarming.|||sex can be boring if it is in the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'good one  _____    course, to which i say i know; that is my blessing and my curse.|||does bein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'dear intp,   i enjoyed our conversation the other day.  esoteric gabbing about the nature of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'you are fired.|||that is another silly misconception. that approaching is logically is going to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  \\\n",
       "0  INFJ   \n",
       "1  ENTP   \n",
       "2  INTP   \n",
       "3  INTJ   \n",
       "4  ENTJ   \n",
       "\n",
       "                                                                                                 posts  \n",
       "0  ' and intj moments    sportscenter not top ten plays    pranks|||what has been the most life-cha...  \n",
       "1  'i am finding the lack of me in these posts very alarming.|||sex can be boring if it is in the s...  \n",
       "2  'good one  _____    course, to which i say i know; that is my blessing and my curse.|||does bein...  \n",
       "3  'dear intp,   i enjoyed our conversation the other day.  esoteric gabbing about the nature of th...  \n",
       "4  'you are fired.|||that is another silly misconception. that approaching is logically is going to...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entries of user's post is separated with a |||. Here we'll have a column to separate the posts in entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>separate_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>' and intj moments    sportscenter not top ten plays    pranks|||what has been the most life-cha...</td>\n",
       "      <td>[' and intj moments    sportscenter not top ten plays    pranks, what has been the most life-cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'i am finding the lack of me in these posts very alarming.|||sex can be boring if it is in the s...</td>\n",
       "      <td>['i am finding the lack of me in these posts very alarming., sex can be boring if it is in the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'good one  _____    course, to which i say i know; that is my blessing and my curse.|||does bein...</td>\n",
       "      <td>['good one  _____    course, to which i say i know; that is my blessing and my curse., does bein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'dear intp,   i enjoyed our conversation the other day.  esoteric gabbing about the nature of th...</td>\n",
       "      <td>['dear intp,   i enjoyed our conversation the other day.  esoteric gabbing about the nature of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'you are fired.|||that is another silly misconception. that approaching is logically is going to...</td>\n",
       "      <td>['you are fired., that is another silly misconception. that approaching is logically is going to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  \\\n",
       "0  INFJ   \n",
       "1  ENTP   \n",
       "2  INTP   \n",
       "3  INTJ   \n",
       "4  ENTJ   \n",
       "\n",
       "                                                                                                 posts  \\\n",
       "0  ' and intj moments    sportscenter not top ten plays    pranks|||what has been the most life-cha...   \n",
       "1  'i am finding the lack of me in these posts very alarming.|||sex can be boring if it is in the s...   \n",
       "2  'good one  _____    course, to which i say i know; that is my blessing and my curse.|||does bein...   \n",
       "3  'dear intp,   i enjoyed our conversation the other day.  esoteric gabbing about the nature of th...   \n",
       "4  'you are fired.|||that is another silly misconception. that approaching is logically is going to...   \n",
       "\n",
       "                                                                                        separate_posts  \n",
       "0  [' and intj moments    sportscenter not top ten plays    pranks, what has been the most life-cha...  \n",
       "1  ['i am finding the lack of me in these posts very alarming., sex can be boring if it is in the s...  \n",
       "2  ['good one  _____    course, to which i say i know; that is my blessing and my curse., does bein...  \n",
       "3  ['dear intp,   i enjoyed our conversation the other day.  esoteric gabbing about the nature of t...  \n",
       "4  ['you are fired., that is another silly misconception. that approaching is logically is going to...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['separate_posts'] = df.posts.apply(lambda x : x.split('|||'))  # Develop a column for seperated posts\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expand the data for each user and entries\n",
    "A user ID is assigned to their respective posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a user ID from the index\n",
    "df['user'] = df.index       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>separate_posts</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>' and intj moments    sportscenter not top ten plays    pranks|||what has been the most life-cha...</td>\n",
       "      <td>[' and intj moments    sportscenter not top ten plays    pranks, what has been the most life-cha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'i am finding the lack of me in these posts very alarming.|||sex can be boring if it is in the s...</td>\n",
       "      <td>['i am finding the lack of me in these posts very alarming., sex can be boring if it is in the s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'good one  _____    course, to which i say i know; that is my blessing and my curse.|||does bein...</td>\n",
       "      <td>['good one  _____    course, to which i say i know; that is my blessing and my curse., does bein...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'dear intp,   i enjoyed our conversation the other day.  esoteric gabbing about the nature of th...</td>\n",
       "      <td>['dear intp,   i enjoyed our conversation the other day.  esoteric gabbing about the nature of t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'you are fired.|||that is another silly misconception. that approaching is logically is going to...</td>\n",
       "      <td>['you are fired., that is another silly misconception. that approaching is logically is going to...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  \\\n",
       "0  INFJ   \n",
       "1  ENTP   \n",
       "2  INTP   \n",
       "3  INTJ   \n",
       "4  ENTJ   \n",
       "\n",
       "                                                                                                 posts  \\\n",
       "0  ' and intj moments    sportscenter not top ten plays    pranks|||what has been the most life-cha...   \n",
       "1  'i am finding the lack of me in these posts very alarming.|||sex can be boring if it is in the s...   \n",
       "2  'good one  _____    course, to which i say i know; that is my blessing and my curse.|||does bein...   \n",
       "3  'dear intp,   i enjoyed our conversation the other day.  esoteric gabbing about the nature of th...   \n",
       "4  'you are fired.|||that is another silly misconception. that approaching is logically is going to...   \n",
       "\n",
       "                                                                                        separate_posts  \\\n",
       "0  [' and intj moments    sportscenter not top ten plays    pranks, what has been the most life-cha...   \n",
       "1  ['i am finding the lack of me in these posts very alarming., sex can be boring if it is in the s...   \n",
       "2  ['good one  _____    course, to which i say i know; that is my blessing and my curse., does bein...   \n",
       "3  ['dear intp,   i enjoyed our conversation the other day.  esoteric gabbing about the nature of t...   \n",
       "4  ['you are fired., that is another silly misconception. that approaching is logically is going to...   \n",
       "\n",
       "   user  \n",
       "0     0  \n",
       "1     1  \n",
       "2     2  \n",
       "3     3  \n",
       "4     4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a new dataframe to expand the entries of  user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>user</th>\n",
       "      <th>separate_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>[' and intj moments    sportscenter not top ten plays    pranks, what has been the most life-cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>1</td>\n",
       "      <td>['i am finding the lack of me in these posts very alarming., sex can be boring if it is in the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>2</td>\n",
       "      <td>['good one  _____    course, to which i say i know; that is my blessing and my curse., does bein...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  user  \\\n",
       "0  INFJ     0   \n",
       "1  ENTP     1   \n",
       "2  INTP     2   \n",
       "\n",
       "                                                                                        separate_posts  \n",
       "0  [' and intj moments    sportscenter not top ten plays    pranks, what has been the most life-cha...  \n",
       "1  ['i am finding the lack of me in these posts very alarming., sex can be boring if it is in the s...  \n",
       "2  ['good one  _____    course, to which i say i know; that is my blessing and my curse., does bein...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entries are expanded first into columns \n",
    "df_expand = pd.DataFrame(df[['type','user','separate_posts']])\n",
    "df_expand.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0, INFJ)</th>\n",
       "      <td>' and intj moments    sportscenter not top ten plays    pranks</td>\n",
       "      <td>what has been the most life-changing experience in your life?</td>\n",
       "      <td>on repeat for most of today.</td>\n",
       "      <td>may the perc experience immerse you.</td>\n",
       "      <td>the last thing my infj friend posted on his facebook before committing suicide the next day. res...</td>\n",
       "      <td>84389  84390     ...</td>\n",
       "      <td>welcome and stuff.</td>\n",
       "      <td>game. set. match.</td>\n",
       "      <td>prozac, wellbrutin, at least thirty minutes of moving your legs (and i do not mean moving them w...</td>\n",
       "      <td>basically come up with three items you have determined that each type (or whichever types you wa...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, ENTP)</th>\n",
       "      <td>'i am finding the lack of me in these posts very alarming.</td>\n",
       "      <td>sex can be boring if it is in the same position often. for example me and my girlfriend are curr...</td>\n",
       "      <td>giving new meaning to 'game' theory.</td>\n",
       "      <td>hello *entp grin*  that is all it takes. than we converse and they do most of the flirting while...</td>\n",
       "      <td>this + lack of balance and hand eye coordination.</td>\n",
       "      <td>real iq test i score 127. internet iq tests are funny. i score 140s or higher.  now, like the fo...</td>\n",
       "      <td>you know you are an entp when you vanish from a site for a year and a half, return, and find peo...</td>\n",
       "      <td>over think things sometimes. i go by the old sherlock holmes quote.  perhaps, when a man has sp...</td>\n",
       "      <td>cheshirewolf.tumblr.com  so is i :d</td>\n",
       "      <td>400,000+  post</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2, INTP)</th>\n",
       "      <td>'good one  _____    course, to which i say i know; that is my blessing and my curse.</td>\n",
       "      <td>does being absolutely positive that you and your best friend could be an amazing couple count? i...</td>\n",
       "      <td>no, i did not; thank you for a link!</td>\n",
       "      <td>so-called ti-si loop (and it can stem from any current topic/obsession) can be deadly. it is lik...</td>\n",
       "      <td>have you noticed how peculiar vegetation can be? all you have to do is look down at the grass: d...</td>\n",
       "      <td>the smiths – never had no one ever</td>\n",
       "      <td>i often find myself spotting faces on marble tiles/wood.</td>\n",
       "      <td>this 5 year-old sentence is an incredibly accurate and beautiful description.</td>\n",
       "      <td>i have not visited this website in the last 3 years. so whoever reads this (and maybe even remem...</td>\n",
       "      <td>when you sit in your garden until 10:30 pm writing songs, and sing them (together with dozens of...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             0   \\\n",
       "(0, INFJ)                        ' and intj moments    sportscenter not top ten plays    pranks   \n",
       "(1, ENTP)                            'i am finding the lack of me in these posts very alarming.   \n",
       "(2, INTP)  'good one  _____    course, to which i say i know; that is my blessing and my curse.   \n",
       "\n",
       "                                                                                                            1   \\\n",
       "(0, INFJ)                                        what has been the most life-changing experience in your life?   \n",
       "(1, ENTP)  sex can be boring if it is in the same position often. for example me and my girlfriend are curr...   \n",
       "(2, INTP)  does being absolutely positive that you and your best friend could be an amazing couple count? i...   \n",
       "\n",
       "                                             2   \\\n",
       "(0, INFJ)          on repeat for most of today.   \n",
       "(1, ENTP)  giving new meaning to 'game' theory.   \n",
       "(2, INTP)  no, i did not; thank you for a link!   \n",
       "\n",
       "                                                                                                            3   \\\n",
       "(0, INFJ)                                                                 may the perc experience immerse you.   \n",
       "(1, ENTP)  hello *entp grin*  that is all it takes. than we converse and they do most of the flirting while...   \n",
       "(2, INTP)  so-called ti-si loop (and it can stem from any current topic/obsession) can be deadly. it is lik...   \n",
       "\n",
       "                                                                                                            4   \\\n",
       "(0, INFJ)  the last thing my infj friend posted on his facebook before committing suicide the next day. res...   \n",
       "(1, ENTP)                                                    this + lack of balance and hand eye coordination.   \n",
       "(2, INTP)  have you noticed how peculiar vegetation can be? all you have to do is look down at the grass: d...   \n",
       "\n",
       "                                                                                                            5   \\\n",
       "(0, INFJ)                                                                                 84389  84390     ...   \n",
       "(1, ENTP)  real iq test i score 127. internet iq tests are funny. i score 140s or higher.  now, like the fo...   \n",
       "(2, INTP)                                                                   the smiths – never had no one ever   \n",
       "\n",
       "                                                                                                            6   \\\n",
       "(0, INFJ)                                                                                   welcome and stuff.   \n",
       "(1, ENTP)  you know you are an entp when you vanish from a site for a year and a half, return, and find peo...   \n",
       "(2, INTP)                                             i often find myself spotting faces on marble tiles/wood.   \n",
       "\n",
       "                                                                                                            7   \\\n",
       "(0, INFJ)                                                                                    game. set. match.   \n",
       "(1, ENTP)   over think things sometimes. i go by the old sherlock holmes quote.  perhaps, when a man has sp...   \n",
       "(2, INTP)                        this 5 year-old sentence is an incredibly accurate and beautiful description.   \n",
       "\n",
       "                                                                                                            8   \\\n",
       "(0, INFJ)  prozac, wellbrutin, at least thirty minutes of moving your legs (and i do not mean moving them w...   \n",
       "(1, ENTP)                                                                  cheshirewolf.tumblr.com  so is i :d   \n",
       "(2, INTP)  i have not visited this website in the last 3 years. so whoever reads this (and maybe even remem...   \n",
       "\n",
       "                                                                                                            9   \\\n",
       "(0, INFJ)  basically come up with three items you have determined that each type (or whichever types you wa...   \n",
       "(1, ENTP)                                                                                       400,000+  post   \n",
       "(2, INTP)  when you sit in your garden until 10:30 pm writing songs, and sing them (together with dozens of...   \n",
       "\n",
       "           ...    79    80    81    82    83    84    85    86    87    88  \n",
       "(0, INFJ)  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "(1, ENTP)  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "(2, INTP)  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "\n",
       "[3 rows x 89 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expand = pd.DataFrame(df.separate_posts.tolist(), index = df[['user','type']])\n",
    "df_expand.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transpose columns to rows\n",
    "\n",
    "df_expand = df_expand.stack().reset_index()              \n",
    "df_expand.drop('level_1',axis=1,inplace=True)\n",
    "df_expand.rename(columns={0:'clean_posts'},inplace=True)\n",
    "df_expand['user'] = [k for k,_ in df_expand['level_0']]\n",
    "df_expand['type'] = [v for _,v in df_expand['level_0']]\n",
    "df_expand.drop('level_0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_posts</th>\n",
       "      <th>user</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>' and intj moments    sportscenter not top ten plays    pranks</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what has been the most life-changing experience in your life?</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on repeat for most of today.</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>may the perc experience immerse you.</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the last thing my infj friend posted on his facebook before committing suicide the next day. res...</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84389  84390     ...</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>welcome and stuff.</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>game. set. match.</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prozac, wellbrutin, at least thirty minutes of moving your legs (and i do not mean moving them w...</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>basically come up with three items you have determined that each type (or whichever types you wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           clean_posts  \\\n",
       "0                                       ' and intj moments    sportscenter not top ten plays    pranks   \n",
       "1                                        what has been the most life-changing experience in your life?   \n",
       "2                                                                         on repeat for most of today.   \n",
       "3                                                                 may the perc experience immerse you.   \n",
       "4  the last thing my infj friend posted on his facebook before committing suicide the next day. res...   \n",
       "5                                                                                 84389  84390     ...   \n",
       "6                                                                                   welcome and stuff.   \n",
       "7                                                                                    game. set. match.   \n",
       "8  prozac, wellbrutin, at least thirty minutes of moving your legs (and i do not mean moving them w...   \n",
       "9  basically come up with three items you have determined that each type (or whichever types you wa...   \n",
       "\n",
       "   user  type  \n",
       "0     0  INFJ  \n",
       "1     0  INFJ  \n",
       "2     0  INFJ  \n",
       "3     0  INFJ  \n",
       "4     0  INFJ  \n",
       "5     0  INFJ  \n",
       "6     0  INFJ  \n",
       "7     0  INFJ  \n",
       "8     0  INFJ  \n",
       "9     0  INFJ  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expand.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405263, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expand.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Entries reduction\n",
    "Entries that are too short are removed. Here we chose an arbitrary figure. Entries below or euqals to 5 words are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c366176512c34754a01d18b091825a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ebabf0863645f0ad7e4b7045b8e160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=405263), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7254c6cc133749b39a292346804615a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=405263), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ed5d847faa41dba77a22a52b366b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=405263), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the entries for word count\n",
    "tqdm_notebook().pandas()\n",
    "df_expand['tokenized_words'] = df_expand.clean_posts.progress_apply(lambda x: word_tokenize(x))\n",
    "\n",
    "# Lemmantize word\n",
    "df_expand['tokenized_words'] = df_expand['tokenized_words'].progress_apply(lambda x : [WordNetLemmatizer().lemmatize(word) for word in x])\n",
    "\n",
    "df_expand['tokenized'] = df_expand['tokenized_words'].progress_apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       [', and, intj, moment, sportscenter, not, top, ten, play, prank]\n",
       "1                                [what, ha, be, the, most, life-changing, experience, in, your, life, ?]\n",
       "2                                                                  [on, repeat, for, most, of, today, .]\n",
       "3                                                          [may, the, perc, experience, immerse, you, .]\n",
       "4    [the, last, thing, my, infj, friend, post, on, his, facebook, before, commit, suicide, the, next...\n",
       "5                                                                                    [84389, 84390, ...]\n",
       "6                                                                               [welcome, and, stuff, .]\n",
       "7                                                                            [game, ., set, ., match, .]\n",
       "8    [prozac, ,, wellbrutin, ,, at, least, thirty, minute, of, move, your, leg, (, and, i, do, not, m...\n",
       "9    [basically, come, up, with, three, item, you, have, determine, that, each, type, (, or, whicheve...\n",
       "Name: tokenized_words, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmantized the words\n",
    "\n",
    "temp = df_expand['tokenized_words'][0:10]\n",
    "temp.apply(lambda x : [WordNetLemmatizer().lemmatize(i,'v') for i in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entries: 405263\n",
      "Total number of entries: 381421\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_posts</th>\n",
       "      <th>user</th>\n",
       "      <th>type</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>' and intj moments    sportscenter not top ten plays    pranks</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>[', and, intj, moment, sportscenter, not, top, ten, play, prank]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what has been the most life-changing experience in your life?</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>[what, ha, been, the, most, life-changing, experience, in, your, life, ?]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on repeat for most of today.</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>[on, repeat, for, most, of, today, .]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      clean_posts  user  type  \\\n",
       "0  ' and intj moments    sportscenter not top ten plays    pranks     0  INFJ   \n",
       "1   what has been the most life-changing experience in your life?     0  INFJ   \n",
       "2                                    on repeat for most of today.     0  INFJ   \n",
       "\n",
       "                                                             tokenized_words  \\\n",
       "0           [', and, intj, moment, sportscenter, not, top, ten, play, prank]   \n",
       "1  [what, ha, been, the, most, life-changing, experience, in, your, life, ?]   \n",
       "2                                      [on, repeat, for, most, of, today, .]   \n",
       "\n",
       "   tokenized  \n",
       "0         10  \n",
       "1         11  \n",
       "2          7  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep entries that have more than 5 words. \n",
    "\n",
    "print('Total number of entries: {}'.format(df_expand.clean_posts.count())) # total number of entries before reduction\n",
    "df_expand = df_expand[df_expand.tokenized > 5]\n",
    "print('Total number of entries: {}'.format(df_expand.clean_posts.count())) # total number of entries after reduction\n",
    "df_expand.reset_index()\n",
    "df_expand.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Cleaning - second round\n",
    "We setup a dataframe of clean posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejoin as a list for count vectorizing\n",
    "df_clean_posts = df_expand.groupby(['user','type'])['clean_posts'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>type</th>\n",
       "      <th>clean_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>' and intj moments    sportscenter not top ten plays    pranks what has been the most life-chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>'i am finding the lack of me in these posts very alarming. sex can be boring if it is in the sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>INTP</td>\n",
       "      <td>'good one  _____    course, to which i say i know; that is my blessing and my curse. does being ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  type  \\\n",
       "0     0  INFJ   \n",
       "1     1  ENTP   \n",
       "2     2  INTP   \n",
       "\n",
       "                                                                                           clean_posts  \n",
       "0  ' and intj moments    sportscenter not top ten plays    pranks what has been the most life-chang...  \n",
       "1  'i am finding the lack of me in these posts very alarming. sex can be boring if it is in the sam...  \n",
       "2  'good one  _____    course, to which i say i know; that is my blessing and my curse. does being ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_posts = df_clean_posts.reset_index()\n",
    "df_clean_posts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop words. Remove reference to the personality types in posts\n",
    "ptype_in_posts = ['infj', 'entp', 'intp', 'intj', 'entj', 'enfj', 'infp', 'enfp','isfp', 'istp', 'isfj', 'istj', 'estp', \n",
    "              'esfp', 'estj', 'esfj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_r2(text):\n",
    "    text = re.sub(r'\\d',' ',text)                                    # remove digits \n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation),'',text)    # removel punctuation \n",
    "    for word in ptype_in_posts :                                     # remove persnoality type words in post\n",
    "        if word in text:                          \n",
    "            text = text.replace(word,'')\n",
    "    text = re.sub('i','I',text)                                      # Textblob recognizes 'i' as NN(noun), hence, this is set to uppercase 'I' to be recognized as PRP\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cleaned posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_posts.clean_posts = df_clean_posts.clean_posts.apply(clean_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentiment analysis with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee65004e5b46495eae645eff5bc881c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d9f14b7ad1465fbf1d199fb1e046b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8675), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e030fd635649129f1ff61a4af48035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8675), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm_notebook().pandas() # track duration\n",
    "\n",
    "df_sentiment_textblob = pd.DataFrame({'type': df_clean_posts.type})\n",
    "df_sentiment_textblob['polarity'] = df_clean_posts.clean_posts.progress_apply(lambda x : round(TextBlob(str(x)).sentiment.polarity,3))\n",
    "df_sentiment_textblob['subjectivity'] = df_clean_posts.clean_posts.progress_apply(lambda x : round(TextBlob(str(x)).sentiment.subjectivity,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  polarity  subjectivity\n",
       "0  INFJ     0.164         0.496\n",
       "1  ENTP     0.103         0.479\n",
       "2  INTP     0.146         0.580\n",
       "3  INTJ     0.111         0.542\n",
       "4  ENTJ     0.069         0.503"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment_textblob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pronouns count\n",
    "The number of different pronouns used is considered. This is inspired by James W. Pennebaker's Secret Life of Pronoun\n",
    " https://www.secretlifeofpronouns.com/\n",
    "- conjunction\n",
    "- determiner\n",
    "- verb auxillary\n",
    "- personal_pronoun\n",
    "- possessive_pronoun\n",
    "- verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of speech abbrevation https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "•\tCC\tconjunction, coordinating and, or, but      \n",
    "•\tCD\tcardinal number\tfive, three, 13%     \n",
    "•\tDT\tdeterminer\tthe, a, these     \n",
    "•\tEX\texistential there\tthere were six boys     \n",
    "•\tFW\tforeign word\tmais     \n",
    "•\tIN\tconjunction, subordinating or preposition\tof, on, before, unless    \n",
    "•\tJJ\tadjective\tnice, easy    \n",
    "•\tJJR\tadjective, comparative\tnicer, easier    \n",
    "•\tJJS\tadjective, superlative\tnicest, easiest     \n",
    "•\tLS\tlist item marker\t     \n",
    "•\tMD\tverb, modal auxillary\tmay, should     \n",
    "•\tNN\tnoun, singular or mass\ttiger, chair, laughter         \n",
    "•\tNNS\tnoun, plural\ttigers, chairs, insects     \n",
    "•\tNNP\tnoun, proper singular\tGermany, God, Alice     \n",
    "•\tNNPS\tnoun, proper plural\twe met two Christmases ago   \n",
    "\n",
    "•\tPDT\tpredeterminer\tboth his children     \n",
    "•\tPOS\tpossessive ending\t's    \n",
    "•\tPRP\tpronoun, personal\tme, you, it     \n",
    "•\tPRP$\tpronoun, possessive\tmy, your, our     \n",
    "•\tRB\tadverb\textremely, loudly, hard      \n",
    "•\tRBR\tadverb, comparative\tbetter     \n",
    "•\tRBS\tadverb, superlative\tbest     \n",
    "•\tRP\tadverb, particle\tabout, off, up     \n",
    "•\tSYM\tsymbol\t%       \n",
    "\n",
    "•\tTO\tinfinitival to\twhat to do?         \n",
    "•\tUH\tinterjection\toh, oops, gosh         \n",
    "•\tVB\tverb, base form\tthink     \n",
    "•\tVBZ\tverb, 3rd person singular present\tshe thinks          \n",
    "•\tVBP\tverb, non-3rd person singular present\tI think      \n",
    "•\tVBD\tverb, past tense\tthey thought      \n",
    "•\tVBN\tverb, past participle\ta sunken ship      \n",
    "•\tVBG\tverb, gerund or present participle\tthinking is fun      \n",
    "•\tWDT\twh-determiner\twhich, whatever, whichever      \n",
    "•\tWP\twh-pronoun, personal\twhat, who, whom      \n",
    "•\tWP$\twh-pronoun, possessive\twhose, whosever      \n",
    "•\tWRB\twh-adverb\twhere, when     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pronoun = df_clean_posts.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3cc0e639f8c4736bb23b203ab091355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc189026880845fc9379dfe5ddbed31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8675), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e2a1a86b7b4889837862dd3b4909bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8675), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7698312ea64498b300eb923b55b5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8675), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae2bee3b45a4a4d8fcf06808293e10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8675), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fbb6653e024ce1887f4456cf2404d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8675), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dabf40737e4cfeacff973e7767fad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8675), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm_notebook().pandas() # track duration\n",
    "\n",
    "df_pronoun['conjunction'] = df_pronoun.clean_posts.progress_apply(lambda x : len([(v) for k,v in TextBlob(x).tags if v == 'CC']))\n",
    "df_pronoun['determiner'] = df_pronoun.clean_posts.progress_apply(lambda x : len([(v) for k,v in TextBlob(x).tags if v == 'DT']))\n",
    "df_pronoun['verb_aux'] = df_pronoun.clean_posts.progress_apply(lambda x : len([(v) for k,v in TextBlob(x).tags if v == 'MD']))\n",
    "df_pronoun['personal_pron'] = df_pronoun.clean_posts.progress_apply(lambda x : len([(v) for k,v in TextBlob(x).tags if v == 'PRP']))\n",
    "df_pronoun['possessive_pron'] = df_pronoun.clean_posts.progress_apply(lambda x : len([(v) for k,v in TextBlob(x).tags if v == 'UH']))\n",
    "df_pronoun['verb'] = df_pronoun.clean_posts.progress_apply(lambda x : len([(v) for k,v in TextBlob(x).tags if v == 'VB']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pronoun.drop('clean_posts',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum all except verbs which is not a functional noun\n",
    "df_pronoun['function_word_count'] = df_pronoun[['conjunction', 'determiner', 'verb_aux', 'personal_pron','possessive_pron',]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>type</th>\n",
       "      <th>conjunction</th>\n",
       "      <th>determiner</th>\n",
       "      <th>verb_aux</th>\n",
       "      <th>personal_pron</th>\n",
       "      <th>possessive_pron</th>\n",
       "      <th>verb</th>\n",
       "      <th>function_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>41</td>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>INTP</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>19</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>31</td>\n",
       "      <td>87</td>\n",
       "      <td>16</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>33</td>\n",
       "      <td>80</td>\n",
       "      <td>13</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  type  conjunction  determiner  verb_aux  personal_pron  \\\n",
       "0     0  INFJ           12          51         7             33   \n",
       "1     1  ENTP           41          88        10            164   \n",
       "2     2  INTP           26          42        19             83   \n",
       "3     3  INTJ           31          87        16            125   \n",
       "4     4  ENTJ           33          80        13             86   \n",
       "\n",
       "   possessive_pron  verb  function_word_count  \n",
       "0                0    24                  103  \n",
       "1                1    63                  304  \n",
       "2                0    56                  170  \n",
       "3                0    57                  259  \n",
       "4                0    57                  212  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pronoun.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_clean_posts.clean_posts.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cvn = CountVectorizer(max_features=1500,      # set max num of vocabs\n",
    "                      stop_words = 'english',  # we remove the common words\n",
    "                      analyzer=\"word\",\n",
    "                      min_df=0.1)           # ignore 10% of lowest vocab usage\n",
    "\n",
    "model = cvn.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptype</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accept</th>\n",
       "      <th>accurate</th>\n",
       "      <th>act</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>xd</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 716 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ptype  ability  able  absolutely  accept  accurate  act  actual  actually  \\\n",
       "0  INFJ        0     0           0       0         0    0       0         0   \n",
       "1  ENTP        0     1           0       0         0    0       0         0   \n",
       "2  INTP        2     1           2       0         1    0       0         2   \n",
       "3  INTJ        0     2           0       0         0    0       1         2   \n",
       "4  ENTJ        0     0           0       0         0    0       0         1   \n",
       "\n",
       "   add  ...  wrong  wrote  xd  yeah  year  years  yes  yesterday  young  \\\n",
       "0    0  ...      0      0   0     0     0      1    0          0      0   \n",
       "1    0  ...      0      0   0     0     1      0    0          0      0   \n",
       "2    0  ...      0      0   0     0     0      4    1          0      0   \n",
       "3    0  ...      0      0   0     1     0      0    0          0      0   \n",
       "4    0  ...      1      0   1     0     1      0    1          0      0   \n",
       "\n",
       "   younger  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 716 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cvn = pd.DataFrame(model.todense(),columns=cvn.get_feature_names(), )\n",
    "df_cvn.insert(0,'ptype',df_clean_posts.type.values)\n",
    "df_cvn.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TfIDF vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptype</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>abstract</th>\n",
       "      <th>accept</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>accurate</th>\n",
       "      <th>...</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045766</td>\n",
       "      <td>0.098302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.038888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>0.1365</td>\n",
       "      <td>0.047305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.078533</td>\n",
       "      <td>0.073945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ptype  ability      able  absolute  absolutely  abstract  accept  according  \\\n",
       "0  INFJ   0.0000  0.000000  0.000000    0.000000       0.0     0.0        0.0   \n",
       "1  ENTP   0.0000  0.038888  0.000000    0.000000       0.0     0.0        0.0   \n",
       "2  INTP   0.1365  0.047305  0.000000    0.114377       0.0     0.0        0.0   \n",
       "3  INTJ   0.0000  0.078533  0.073945    0.000000       0.0     0.0        0.0   \n",
       "4  ENTJ   0.0000  0.000000  0.000000    0.000000       0.0     0.0        0.0   \n",
       "\n",
       "   account  accurate  ...      yeah      year     years       yep       yes  \\\n",
       "0      0.0  0.000000  ...  0.000000  0.000000  0.045766  0.098302  0.000000   \n",
       "1      0.0  0.000000  ...  0.000000  0.036724  0.000000  0.000000  0.000000   \n",
       "2      0.0  0.068651  ...  0.000000  0.000000  0.144245  0.000000  0.032915   \n",
       "3      0.0  0.000000  ...  0.032796  0.000000  0.000000  0.000000  0.000000   \n",
       "4      0.0  0.000000  ...  0.000000  0.036683  0.000000  0.000000  0.027028   \n",
       "\n",
       "   yesterday  young  younger  youtube       yup  \n",
       "0        0.0    0.0      0.0      0.0  0.000000  \n",
       "1        0.0    0.0      0.0      0.0  0.000000  \n",
       "2        0.0    0.0      0.0      0.0  0.089335  \n",
       "3        0.0    0.0      0.0      0.0  0.000000  \n",
       "4        0.0    0.0      0.0      0.0  0.000000  \n",
       "\n",
       "[5 rows x 1375 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1500,       # set max num of vocabs\n",
    "                        stop_words = 'english',  # we remove the common words\n",
    "                        analyzer=\"word\",           \n",
    "                        min_df=0.05)             # Consider only words used 95% ot the time\n",
    "\n",
    "model = tfidf.fit_transform(corpus)\n",
    "\n",
    "df_tfidf = pd.DataFrame(model.todense(),columns=tfidf.get_feature_names())\n",
    "df_tfidf.insert(0,'ptype',df_clean_posts.type.values)\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = pd.DataFrame(df_clean_posts.type.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target['world_E_I'] = df_target.type.apply(lambda x: 1 if x[0] == 'E' else 0)\n",
    "df_target['information_S_N'] = df_target.type.apply(lambda x: 1 if x[1] == 'S' else 0)\n",
    "df_target['decision_T_F'] = df_target.type.apply(lambda x: 1 if x[2] == 'T' else 0)\n",
    "df_target['structure_J_P'] = df_target.type.apply(lambda x: 1 if x[3] == 'J' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_posts</th>\n",
       "      <th>user</th>\n",
       "      <th>type</th>\n",
       "      <th>tokenized_words</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>' and intj moments    sportscenter not top ten plays    pranks</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>[', and, intj, moment, sportscenter, not, top, ten, play, prank]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what has been the most life-changing experience in your life?</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>[what, ha, been, the, most, life-changing, experience, in, your, life, ?]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on repeat for most of today.</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>[on, repeat, for, most, of, today, .]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>may the perc experience immerse you.</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>[may, the, perc, experience, immerse, you, .]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the last thing my infj friend posted on his facebook before committing suicide the next day. res...</td>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>[the, last, thing, my, infj, friend, posted, on, his, facebook, before, committing, suicide, the...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           clean_posts  \\\n",
       "0                                       ' and intj moments    sportscenter not top ten plays    pranks   \n",
       "1                                        what has been the most life-changing experience in your life?   \n",
       "2                                                                         on repeat for most of today.   \n",
       "3                                                                 may the perc experience immerse you.   \n",
       "4  the last thing my infj friend posted on his facebook before committing suicide the next day. res...   \n",
       "\n",
       "   user  type  \\\n",
       "0     0  INFJ   \n",
       "1     0  INFJ   \n",
       "2     0  INFJ   \n",
       "3     0  INFJ   \n",
       "4     0  INFJ   \n",
       "\n",
       "                                                                                       tokenized_words  \\\n",
       "0                                     [', and, intj, moment, sportscenter, not, top, ten, play, prank]   \n",
       "1                            [what, ha, been, the, most, life-changing, experience, in, your, life, ?]   \n",
       "2                                                                [on, repeat, for, most, of, today, .]   \n",
       "3                                                        [may, the, perc, experience, immerse, you, .]   \n",
       "4  [the, last, thing, my, infj, friend, posted, on, his, facebook, before, committing, suicide, the...   \n",
       "\n",
       "   tokenized  \n",
       "0         10  \n",
       "1         11  \n",
       "2          7  \n",
       "3          7  \n",
       "4         62  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expand[df_expand.user == 0].tokenized.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_count\n",
       "user            \n",
       "0            668\n",
       "1           1419\n",
       "2           1025\n",
       "3           1326\n",
       "4           1153"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words_count_per_user = df_expand.groupby('user')['tokenized'].sum()\n",
    "df_wordcounts = pd.DataFrame(total_words_count_per_user)\n",
    "df_wordcounts.rename(columns={'tokenized':'word_count'},inplace=True)\n",
    "df_wordcounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>num_of_entries</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>668</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1025</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1326</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1153</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_count  num_of_entries\n",
       "user                            \n",
       "0            668              31\n",
       "1           1419              43\n",
       "2           1025              37\n",
       "3           1326              44\n",
       "4           1153              38"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wordcounts['num_of_entries'] = df_expand.groupby('user')['clean_posts'].count()\n",
    "df_wordcounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wordcounts['avg_words_post'] = np.floor(df_wordcounts.word_count/df_wordcounts.num_of_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>num_of_entries</th>\n",
       "      <th>avg_words_post</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>668</td>\n",
       "      <td>31</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1419</td>\n",
       "      <td>43</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1025</td>\n",
       "      <td>37</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1326</td>\n",
       "      <td>44</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1153</td>\n",
       "      <td>38</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_count  num_of_entries  avg_words_post\n",
       "user                                            \n",
       "0            668              31            21.0\n",
       "1           1419              43            33.0\n",
       "2           1025              37            27.0\n",
       "3           1326              44            30.0\n",
       "4           1153              38            30.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wordcounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### final cleaning to columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_posts.rename(columns={'type':'ptype'},inplace=True)\n",
    "df_sentiment_textblob.rename(columns={'type':'ptype'},inplace=True)\n",
    "df_pronoun.rename(columns={'type':'ptype'},inplace=True)\n",
    "df_target.rename(columns={'type':'ptype'},inplace=True)\n",
    "df_wordcounts.rename(columns={'type':'ptype'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Putting dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merge_clean_posts = pd.concat([df_target,\n",
    "                                  df_clean_posts['clean_posts'],\n",
    "                                  df_sentiment_textblob[['polarity', 'subjectivity']],\n",
    "                                  df_pronoun[['conjunction', 'determiner', 'verb_aux','personal_pron', 'possessive_pron', 'verb', 'function_word_count']],\n",
    "                                  df_wordcounts],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ptype</th>\n",
       "      <th>world_E_I</th>\n",
       "      <th>information_S_N</th>\n",
       "      <th>decision_T_F</th>\n",
       "      <th>structure_J_P</th>\n",
       "      <th>clean_posts</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>conjunction</th>\n",
       "      <th>determiner</th>\n",
       "      <th>verb_aux</th>\n",
       "      <th>personal_pron</th>\n",
       "      <th>possessive_pron</th>\n",
       "      <th>verb</th>\n",
       "      <th>function_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>num_of_entries</th>\n",
       "      <th>avg_words_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>and  moments    sportscenter not top ten plays    pranks what has been the most lIfechangIng ex...</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.496</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>103</td>\n",
       "      <td>668</td>\n",
       "      <td>31</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I am fIndIng the lack of me In these posts very alarmIng sex can be borIng If It Is In the same ...</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.479</td>\n",
       "      <td>41</td>\n",
       "      <td>88</td>\n",
       "      <td>10</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>304</td>\n",
       "      <td>1419</td>\n",
       "      <td>43</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good one      course to whIch I say I know that Is my blessIng and my curse does beIng absolutel...</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.580</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>19</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>170</td>\n",
       "      <td>1025</td>\n",
       "      <td>37</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ptype  world_E_I  information_S_N  decision_T_F  structure_J_P  \\\n",
       "0  INFJ          0                0             0              1   \n",
       "1  ENTP          1                0             1              0   \n",
       "2  INTP          0                0             1              0   \n",
       "\n",
       "                                                                                           clean_posts  \\\n",
       "0   and  moments    sportscenter not top ten plays    pranks what has been the most lIfechangIng ex...   \n",
       "1  I am fIndIng the lack of me In these posts very alarmIng sex can be borIng If It Is In the same ...   \n",
       "2  good one      course to whIch I say I know that Is my blessIng and my curse does beIng absolutel...   \n",
       "\n",
       "   polarity  subjectivity  conjunction  determiner  verb_aux  personal_pron  \\\n",
       "0     0.164         0.496           12          51         7             33   \n",
       "1     0.103         0.479           41          88        10            164   \n",
       "2     0.146         0.580           26          42        19             83   \n",
       "\n",
       "   possessive_pron  verb  function_word_count  word_count  num_of_entries  \\\n",
       "0                0    24                  103         668              31   \n",
       "1                1    63                  304        1419              43   \n",
       "2                0    56                  170        1025              37   \n",
       "\n",
       "   avg_words_post  \n",
       "0            21.0  \n",
       "1            33.0  \n",
       "2            27.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_clean_posts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_tfidf = pd.concat([df_target,df_tfidf.drop('ptype',axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_cvn = pd.concat([df_target,df_cvn.drop('ptype',axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_clean_posts.to_csv('df_merge_clean_posts.csv')\n",
    "df_merge_tfidf.to_csv('df_merge_tfidf.csv')\n",
    "df_merge_cvn.to_csv('df_merge_cvn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentiment analysis with Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyser = SentimentIntensityAnalyzer()\n",
    "# df_sentiment_vader = df_clean_posts.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tqdm_notebook().pandas()\n",
    "# df_sentiment_vader['sentiment'] = df_sentiment_vader.clean_posts.progress_apply(lambda x : analyser.polarity_scores(str(x)))\n",
    "\n",
    "# df_sentiment_vader['neg'] = df_sentiment_vader.sentiment.progress_apply(lambda x : x['neg'])\n",
    "# df_sentiment_vader['neu'] = df_sentiment_vader.sentiment.progress_apply(lambda x : x['neu'])\n",
    "# df_sentiment_vader['pos'] = df_sentiment_vader.sentiment.progress_apply(lambda x : x['pos'])\n",
    "# df_sentiment_vader['compound'] = df_sentiment_vader.sentiment.progress_apply(lambda x : x['compound'])\n",
    "\n",
    "# df_sentiment_vader.drop(['sentiment','clean_posts'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
